{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - Best Match Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading file\n",
    "讀取 Document 和 Query，並將內容以切割成文章單字列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list_filename = 'data/doc_list.txt'  # doc_list 檔案路徑\n",
    "query_list_filename = 'data/query_list.txt'  # query_list 檔案路徑\n",
    "doc_path = 'data/docs/'  # document 檔案資料夾路徑\n",
    "query_path = 'data/queries/'  # query 檔案資料夾路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = pd.read_table(doc_list_filename, header=None)[0].tolist()\n",
    "query_list = pd.read_table(query_list_filename, header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_split(file_path, file_list, description):\n",
    "    text_list = []\n",
    "    text_split_list = []\n",
    "    pbar = tqdm(file_list)  # 進度條\n",
    "    pbar.set_description('Reading %s' % description)\n",
    "    for file in pbar:\n",
    "        filename = file_path + str(file) + '.txt'\n",
    "        try:\n",
    "            text = pd.read_table(filename, header=None)[0][0]  # 只讀取檔案的第一行\n",
    "        except:\n",
    "            text = ''\n",
    "        text_list.append(text)  # 檔案完整內容\n",
    "        text_split_list.append(text.split())  # 檔案內容切成單字列表\n",
    "    return text_list, text_split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfce357dec64dbcbd31a9cdee5eb249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4191), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc415968bfd943edbea554b7630f567e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_text, doc_text_split = read_and_split(doc_path ,doc_list, 'doc')\n",
    "query_text, query_text_split = read_and_split(query_path ,query_list, 'query')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index term\n",
    "將 Document 與 Query 各文章單字列表合併，去除重複得到 Index term。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_remove_duplicates(data_list):\n",
    "    t_list = []\n",
    "    for data in data_list:\n",
    "        t_list += data\n",
    "    t_dict = {}.fromkeys(t_list)  # 利用 Dictionary key 不重複的特性，取得 Index Term\n",
    "    return list(t_dict)  # 將 Dictionary 轉成 List 回傳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_term = list_remove_duplicates(doc_text_split + query_text_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency & Inverse Document Frequency\n",
    "由於 homework2 的資料集與 homework1 相同，因此直接載入 Term Frequency 與 Inverse Document Frequency 的資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tf_matrix = np.load('doc_tf_matrix.npy')\n",
    "query_tf_matrix = np.load('query_tf_matrix.npy')\n",
    "doc_df_matrix = np.load('doc_df_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idf_matrix = np.log((len(doc_text_split)-doc_df_matrix+0.5)/(doc_df_matrix+0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Match Models (BM25)\n",
    "+ $sim_{BM25}(d_{j},q) \\equiv \\sum_{w_i=\\in\\{d_j\\cap q\\}}^{} \\frac{(K_1+1) \\times tf_{ij}}{K_1[(1-b) + b \\times \\frac{len(d_j)}{avg_{doclen}}]+tf_{ij}} \\times \\frac{(K_3+1) \\times tf_{i,q}}{K_3 + tf_{i,q}} \\times log(\\frac{N-n_i + 0.5}{n_i + 0.5})$\n",
    "    + $K_1 = 1.8$\n",
    "    + $K_3 = 1500$\n",
    "    + $b = 0.85$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 1.8\n",
    "k3 = 1500\n",
    "b = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_doclen = sum([len(doc) for doc in doc_text_split]) / len(doc_text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9273b7a4bcdf4f5daa4d0daa1e49b53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(len(query_text_split)))  # 進度條\n",
    "pbar.set_description('BM25')\n",
    "\n",
    "sim_matrix = []\n",
    "for query_index in pbar:\n",
    "    query_doc_sim = []\n",
    "    for doc_index in range(len(doc_text_split)):\n",
    "        sim = 0\n",
    "        for query in query_text_split[query_index]:\n",
    "            if query in doc_text_split[doc_index]:\n",
    "                word_index = index_term.index(query)\n",
    "                # BM25\n",
    "                v1 = ((k1 + 1) * doc_tf_matrix[doc_index][word_index])/(k1 * ((1-b) + b*len(doc_text_split[doc_index])/avg_doclen) + doc_tf_matrix[doc_index][word_index])\n",
    "                v2 = ((k3 + 1) * query_tf_matrix[query_index][word_index])/(k3 + query_tf_matrix[query_index][word_index])\n",
    "                v3 = doc_idf_matrix[word_index]\n",
    "                sim += (v1 * v2 * v3)\n",
    "        query_doc_sim.append(sim)\n",
    "    sim_matrix.append(query_doc_sim)\n",
    "sim_matrix = np.array(sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank\n",
    "1. 根據剛剛的 Cosine similarity Matrix，可以把每個 Query 與所有 Document 的相似程度做排名，並把排名結果以 Document 檔名依序列出，存成一個 Retrieved Documents List。\n",
    "2. 把 Query List 和 Retrieved Documents List 建成一個 DatafFrame，輸出成 CSV。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015a6b8192074d0eb605e608a3fef0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_documents_list = []\n",
    "\n",
    "pbar = tqdm(range(sim_matrix.shape[0]))\n",
    "pbar.set_description('Ranking')\n",
    "for i in pbar:\n",
    "    # np.argsort(np.argsort(Vector)) 可得到該 Value 在此 Vector 的名次(越大名次越高)\n",
    "    retrie_doc_value_dict = dict(zip(doc_list, np.argsort(np.argsort(sim_matrix[i]))))\n",
    "    # 將 (key, value) 根據 Value 進行排序，輸出 key\n",
    "    retrie_doc_sort_list = sorted(retrie_doc_value_dict.items(),\n",
    "                                                                  key=lambda retrie_doc_value_dict:retrie_doc_value_dict[1], \n",
    "                                                                  reverse = True)\n",
    "    # 將每個 key 以空格分隔輸出成 String 放至 Retrieved Documents List\n",
    "    retrieved_documents_list.append(' '.join([doc[0] for doc in retrie_doc_sort_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>RetrievedDocuments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>FBIS3-23986 FBIS4-7811 FBIS3-21961 FBIS3-19646...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>LA043090-0036 FBIS4-67701 FBIS4-30637 LA031489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>FT921-7107 LA122990-0029 FT944-128 FT931-6554 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>304</td>\n",
       "      <td>FR940617-0-00104 FR940706-2-00012 FR941006-2-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>305</td>\n",
       "      <td>LA031689-0177 FT944-18875 FBIS4-45230 FBIS4-44...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Query                                 RetrievedDocuments\n",
       "0    301  FBIS3-23986 FBIS4-7811 FBIS3-21961 FBIS3-19646...\n",
       "1    302  LA043090-0036 FBIS4-67701 FBIS4-30637 LA031489...\n",
       "2    303  FT921-7107 LA122990-0029 FT944-128 FT931-6554 ...\n",
       "3    304  FR940617-0-00104 FR940706-2-00012 FR941006-2-0...\n",
       "4    305  LA031689-0177 FT944-18875 FBIS4-45230 FBIS4-44..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 存成 DataFrame \n",
    "submission_df = pd.DataFrame(data={'Query': query_list,\n",
    "                                                                               'RetrievedDocuments': retrieved_documents_list})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出成 CSV\n",
    "submission_df.to_csv('submission_hw2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
