{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 - Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading file\n",
    "讀取 Document 和 Query，並將內容以切割成文章單字列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list_filename = 'data/doc_list.txt'  # doc_list 檔案路徑\n",
    "query_list_filename = 'data/query_list.txt'  # query_list 檔案路徑\n",
    "doc_path = 'data/docs/'  # document 檔案資料夾路徑\n",
    "query_path = 'data/queries/'  # query 檔案資料夾路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = pd.read_table(doc_list_filename, header=None)[0].tolist()\n",
    "query_list = pd.read_table(query_list_filename, header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_split(file_path, file_list, description):\n",
    "    text_list = []\n",
    "    text_split_list = []\n",
    "    pbar = tqdm(file_list)  # 進度條\n",
    "    pbar.set_description('Reading %s' % description)\n",
    "    for file in pbar:\n",
    "        filename = file_path + str(file) + '.txt'\n",
    "        try:\n",
    "            text = pd.read_table(filename, header=None)[0][0]  # 只讀取檔案的第一行\n",
    "        except:\n",
    "            text = ''\n",
    "        text_list.append(text)  # 檔案完整內容\n",
    "        text_split_list.append(text.split())  # 檔案內容切成單字列表\n",
    "    return text_list, text_split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text, doc_text_split = read_and_split(doc_path ,doc_list, 'doc')\n",
    "query_text, query_text_split = read_and_split(query_path ,query_list, 'query')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index term\n",
    "將 Document 與 Query 各文章單字列表合併，去除重複得到 Index term。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_remove_duplicates(data_list):\n",
    "    t_list = []\n",
    "    for data in data_list:\n",
    "        t_list += data\n",
    "    t_dict = {}.fromkeys(t_list)  # 利用 Dictionary key 不重複的特性，取得 Index Term\n",
    "    return list(t_dict)  # 將 Dictionary 轉成 List 回傳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_term = list_remove_duplicates(doc_text_split + query_text_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency\n",
    "根據剛剛的 Index Term 列表，統計各 Document & Query 出現每個在 Index Term 中 Word 的次數。\n",
    "\n",
    "+ ${Term\\;Frequency}=tf_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(index_term, document):\n",
    "    doc_matrix = []\n",
    "    pbar = tqdm(document)  # 進度條\n",
    "    pbar.set_description('TF')\n",
    "    for doc in pbar:\n",
    "        doc_vector = []\n",
    "        for word in index_term:  # 根據 Index Term 中每個 Word\n",
    "            doc_vector.append(doc.count(word))  # 計數該 Word 在這個 Document 出現幾次\n",
    "        doc_matrix.append(doc_vector)\n",
    "    return np.array(doc_matrix)  # 將 2D list 轉成 Numpy.array 回傳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由於計算Term Frequency非常耗時，\n",
    "# 因此可將這兩個 matrix 存起來，方便重複使用，直接對此 Matrix 套入公式調整 TF Matrix\n",
    "doc_tf_matrix = term_frequency(index_term, doc_text_split)\n",
    "np.save('doc_tf_matrix', doc_tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tf_matrix = term_frequency(index_term, query_text_split)\n",
    "np.save('query_tf_matrix', query_tf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency\n",
    "目的是想知道每個 Word 的「獨特性」。\n",
    "\n",
    "1. 我們首先計算每個 Word 在出現在各 Document 的頻率，得到 Document Frequency Matrix。\n",
    "\n",
    "2. 再將 Document Frequency Matrix 轉成 Inverse Document Frequency Matrix。\n",
    "\n",
    "+ ${Document\\;Frequency}=\\frac{N}{n_{i}}$\n",
    "+ ${Inverse\\;Document\\;Frequency}=log(1+\\frac{N+1}{n_{i}+1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_frequency(index_term, document):\n",
    "    df_list = []\n",
    "    num_of_doc = len(document)\n",
    "    pbar = tqdm(index_term)\n",
    "    pbar.set_description('DF')\n",
    "    for word in pbar:\n",
    "        doc_count = 0\n",
    "        for doc in document:\n",
    "            if word in doc:\n",
    "                doc_count += 1\n",
    "        df_list.append(doc_count)  # df weight\n",
    "    return np.array(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df_matrix = document_frequency(index_term, doc_text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分子分母皆加一，避免除零錯誤\n",
    "doc_idf_matrix = 1 + np.log((len(doc_text_split)+1)/(doc_df_matrix+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由於計算Term Frequency也相當耗時，\n",
    "# 因此可將可 matrix 存起來，方便重複使用，直接對此 Matrix 套入公式調整 IDF Matrix\n",
    "np.save('doc_df_matrix', doc_df_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "將 TF Matrix 和 IDF Matrix 相乘，即可得到 TF-IDF Matrix，每個 Document & Query 皆有一個代表它的向量。\n",
    "+ $𝑇𝐹−𝐼𝐷𝐹_{𝑖,𝑗}=𝑡𝑓_{𝑖,𝑗}\\times𝑖𝑑𝑓_{𝑖}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tf_matrix = np.load('doc_tf_matrix.npy')\n",
    "query_tf_matrix = np.load('query_tf_matrix.npy')\n",
    "doc_df_matrix = np.load('doc_df_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tf_idf_matrix = doc_tf_matrix * doc_idf_matrix\n",
    "query_tf_idf_matrix = query_tf_matrix * doc_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity\n",
    "計算餘弦相似性，得出每個 Query 與各 Document 的相似程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_matrix = cosine_similarity(query_tf_idf_matrix, doc_tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank\n",
    "1. 根據剛剛的 Cosine similarity Matrix，可以把每個 Query 與所有 Document 的相似程度做排名，並把排名結果以 Document 檔名依序列出，存成一個 Retrieved Documents List。\n",
    "2. 把 Query List 和 Retrieved Documents List 建成一個 DatafFrame，輸出成 CSV。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents_list = []\n",
    "\n",
    "pbar = tqdm(range(cos_matrix.shape[0]))\n",
    "pbar.set_description('Ranking')\n",
    "for i in pbar:\n",
    "    # np.argsort(np.argsort(Vector)) 可得到該 Value 在此 Vector 的名次(越大名次越高)\n",
    "    retrie_doc_value_dict = dict(zip(doc_list, np.argsort(np.argsort(cos_matrix[i]))))\n",
    "    # 將 (key, value) 根據 Value 進行排序，輸出 key\n",
    "    retrie_doc_sort_list = sorted(retrie_doc_value_dict.items(),\n",
    "                                                                  key=lambda retrie_doc_value_dict:retrie_doc_value_dict[1], \n",
    "                                                                  reverse = True)\n",
    "    # 將每個 key 以空格分隔輸出成 String 放至 Retrieved Documents List\n",
    "    retrieved_documents_list.append(' '.join([doc[0] for doc in retrie_doc_sort_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存成 DataFrame \n",
    "submission_df = pd.DataFrame(data={'Query': query_list,\n",
    "                                                                               'RetrievedDocuments': retrieved_documents_list})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出成 CSV\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
