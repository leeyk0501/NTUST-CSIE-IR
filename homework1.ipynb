{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 - Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading file\n",
    "è®€å– Document å’Œ Queryï¼Œä¸¦å°‡å…§å®¹ä»¥åˆ‡å‰²æˆæ–‡ç« å–®å­—åˆ—è¡¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list_filename = 'data/doc_list.txt'  # doc_list æª”æ¡ˆè·¯å¾‘\n",
    "query_list_filename = 'data/query_list.txt'  # query_list æª”æ¡ˆè·¯å¾‘\n",
    "doc_path = 'data/docs/'  # document æª”æ¡ˆè³‡æ–™å¤¾è·¯å¾‘\n",
    "query_path = 'data/queries/'  # query æª”æ¡ˆè³‡æ–™å¤¾è·¯å¾‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = pd.read_table(doc_list_filename, header=None)[0].tolist()\n",
    "query_list = pd.read_table(query_list_filename, header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_split(file_path, file_list, description):\n",
    "    text_list = []\n",
    "    text_split_list = []\n",
    "    pbar = tqdm(file_list)  # é€²åº¦æ¢\n",
    "    pbar.set_description('Reading %s' % description)\n",
    "    for file in pbar:\n",
    "        filename = file_path + str(file) + '.txt'\n",
    "        try:\n",
    "            text = pd.read_table(filename, header=None)[0][0]  # åªè®€å–æª”æ¡ˆçš„ç¬¬ä¸€è¡Œ\n",
    "        except:\n",
    "            text = ''\n",
    "        text_list.append(text)  # æª”æ¡ˆå®Œæ•´å…§å®¹\n",
    "        text_split_list.append(text.split())  # æª”æ¡ˆå…§å®¹åˆ‡æˆå–®å­—åˆ—è¡¨\n",
    "    return text_list, text_split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text, doc_text_split = read_and_split(doc_path ,doc_list, 'doc')\n",
    "query_text, query_text_split = read_and_split(query_path ,query_list, 'query')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index term\n",
    "å°‡ Document èˆ‡ Query å„æ–‡ç« å–®å­—åˆ—è¡¨åˆä½µï¼Œå»é™¤é‡è¤‡å¾—åˆ° Index termã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_remove_duplicates(data_list):\n",
    "    t_list = []\n",
    "    for data in data_list:\n",
    "        t_list += data\n",
    "    t_dict = {}.fromkeys(t_list)  # åˆ©ç”¨ Dictionary key ä¸é‡è¤‡çš„ç‰¹æ€§ï¼Œå–å¾— Index Term\n",
    "    return list(t_dict)  # å°‡ Dictionary è½‰æˆ List å›å‚³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_term = list_remove_duplicates(doc_text_split + query_text_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency\n",
    "æ ¹æ“šå‰›å‰›çš„ Index Term åˆ—è¡¨ï¼Œçµ±è¨ˆå„ Document & Query å‡ºç¾æ¯å€‹åœ¨ Index Term ä¸­ Word çš„æ¬¡æ•¸ã€‚\n",
    "\n",
    "+ ${Term\\;Frequency}=tf_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(index_term, document):\n",
    "    doc_matrix = []\n",
    "    pbar = tqdm(document)  # é€²åº¦æ¢\n",
    "    pbar.set_description('TF')\n",
    "    for doc in pbar:\n",
    "        doc_vector = []\n",
    "        for word in index_term:  # æ ¹æ“š Index Term ä¸­æ¯å€‹ Word\n",
    "            doc_vector.append(doc.count(word))  # è¨ˆæ•¸è©² Word åœ¨é€™å€‹ Document å‡ºç¾å¹¾æ¬¡\n",
    "        doc_matrix.append(doc_vector)\n",
    "    return np.array(doc_matrix)  # å°‡ 2D list è½‰æˆ Numpy.array å›å‚³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”±æ–¼è¨ˆç®—Term Frequencyéå¸¸è€—æ™‚ï¼Œ\n",
    "# å› æ­¤å¯å°‡é€™å…©å€‹ matrix å­˜èµ·ä¾†ï¼Œæ–¹ä¾¿é‡è¤‡ä½¿ç”¨ï¼Œç›´æ¥å°æ­¤ Matrix å¥—å…¥å…¬å¼èª¿æ•´ TF Matrix\n",
    "doc_tf_matrix = term_frequency(index_term, doc_text_split)\n",
    "np.save('doc_tf_matrix', doc_tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tf_matrix = term_frequency(index_term, query_text_split)\n",
    "np.save('query_tf_matrix', query_tf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency\n",
    "ç›®çš„æ˜¯æƒ³çŸ¥é“æ¯å€‹ Word çš„ã€Œç¨ç‰¹æ€§ã€ã€‚\n",
    "\n",
    "1. æˆ‘å€‘é¦–å…ˆè¨ˆç®—æ¯å€‹ Word åœ¨å‡ºç¾åœ¨å„ Document çš„é »ç‡ï¼Œå¾—åˆ° Document Frequency Matrixã€‚\n",
    "\n",
    "2. å†å°‡ Document Frequency Matrix è½‰æˆ Inverse Document Frequency Matrixã€‚\n",
    "\n",
    "+ ${Document\\;Frequency}=\\frac{N}{n_{i}}$\n",
    "+ ${Inverse\\;Document\\;Frequency}=log(1+\\frac{N+1}{n_{i}+1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_frequency(index_term, document):\n",
    "    df_list = []\n",
    "    num_of_doc = len(document)\n",
    "    pbar = tqdm(index_term)\n",
    "    pbar.set_description('DF')\n",
    "    for word in pbar:\n",
    "        doc_count = 0\n",
    "        for doc in document:\n",
    "            if word in doc:\n",
    "                doc_count += 1\n",
    "        df_list.append(doc_count)  # df weight\n",
    "    return np.array(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df_matrix = document_frequency(index_term, doc_text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†å­åˆ†æ¯çš†åŠ ä¸€ï¼Œé¿å…é™¤é›¶éŒ¯èª¤\n",
    "doc_idf_matrix = 1 + np.log((len(doc_text_split)+1)/(doc_df_matrix+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”±æ–¼è¨ˆç®—Term Frequencyä¹Ÿç›¸ç•¶è€—æ™‚ï¼Œ\n",
    "# å› æ­¤å¯å°‡å¯ matrix å­˜èµ·ä¾†ï¼Œæ–¹ä¾¿é‡è¤‡ä½¿ç”¨ï¼Œç›´æ¥å°æ­¤ Matrix å¥—å…¥å…¬å¼èª¿æ•´ IDF Matrix\n",
    "np.save('doc_df_matrix', doc_df_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "å°‡ TF Matrix å’Œ IDF Matrix ç›¸ä¹˜ï¼Œå³å¯å¾—åˆ° TF-IDF Matrixï¼Œæ¯å€‹ Document & Query çš†æœ‰ä¸€å€‹ä»£è¡¨å®ƒçš„å‘é‡ã€‚\n",
    "+ $ğ‘‡ğ¹âˆ’ğ¼ğ·ğ¹_{ğ‘–,ğ‘—}=ğ‘¡ğ‘“_{ğ‘–,ğ‘—}\\timesğ‘–ğ‘‘ğ‘“_{ğ‘–}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tf_matrix = np.load('doc_tf_matrix.npy')\n",
    "query_tf_matrix = np.load('query_tf_matrix.npy')\n",
    "doc_df_matrix = np.load('doc_df_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tf_idf_matrix = doc_tf_matrix * doc_idf_matrix\n",
    "query_tf_idf_matrix = query_tf_matrix * doc_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity\n",
    "è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼æ€§ï¼Œå¾—å‡ºæ¯å€‹ Query èˆ‡å„ Document çš„ç›¸ä¼¼ç¨‹åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_matrix = cosine_similarity(query_tf_idf_matrix, doc_tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank\n",
    "1. æ ¹æ“šå‰›å‰›çš„ Cosine similarity Matrixï¼Œå¯ä»¥æŠŠæ¯å€‹ Query èˆ‡æ‰€æœ‰ Document çš„ç›¸ä¼¼ç¨‹åº¦åšæ’åï¼Œä¸¦æŠŠæ’åçµæœä»¥ Document æª”åä¾åºåˆ—å‡ºï¼Œå­˜æˆä¸€å€‹ Retrieved Documents Listã€‚\n",
    "2. æŠŠ Query List å’Œ Retrieved Documents List å»ºæˆä¸€å€‹ DatafFrameï¼Œè¼¸å‡ºæˆ CSVã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents_list = []\n",
    "\n",
    "pbar = tqdm(range(cos_matrix.shape[0]))\n",
    "pbar.set_description('Ranking')\n",
    "for i in pbar:\n",
    "    # np.argsort(np.argsort(Vector)) å¯å¾—åˆ°è©² Value åœ¨æ­¤ Vector çš„åæ¬¡(è¶Šå¤§åæ¬¡è¶Šé«˜)\n",
    "    retrie_doc_value_dict = dict(zip(doc_list, np.argsort(np.argsort(cos_matrix[i]))))\n",
    "    # å°‡ (key, value) æ ¹æ“š Value é€²è¡Œæ’åºï¼Œè¼¸å‡º key\n",
    "    retrie_doc_sort_list = sorted(retrie_doc_value_dict.items(),\n",
    "                                                                  key=lambda retrie_doc_value_dict:retrie_doc_value_dict[1], \n",
    "                                                                  reverse = True)\n",
    "    # å°‡æ¯å€‹ key ä»¥ç©ºæ ¼åˆ†éš”è¼¸å‡ºæˆ String æ”¾è‡³ Retrieved Documents List\n",
    "    retrieved_documents_list.append(' '.join([doc[0] for doc in retrie_doc_sort_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­˜æˆ DataFrame \n",
    "submission_df = pd.DataFrame(data={'Query': query_list,\n",
    "                                                                               'RetrievedDocuments': retrieved_documents_list})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼¸å‡ºæˆ CSV\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
